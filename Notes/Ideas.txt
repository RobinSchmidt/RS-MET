SmoothedValue:
-see class juce::LinearSmoothedValue
-generalize to an update equation: x[n+1] = a*x[n] + b
-allows for linear and exponential smoothing and anything between
-general term is: 
 x[n] = a^n * x[0] + b * sum_{k=0}^{n-1} a^n 
      = a^n * x0   + b * n * a^n 
	  = a^n * (x0 + b*n)
-maybe we can have a kind of "exponentiality" parameter p between 0..1
 with 0, we have linear scaling (a = 1), with 1 exponential (b = 0)
 maybe a = 1-p, b = p * c (for some suitable c, maybe 1/N (?) where N 
 is the desired number of updates to reach the target)

CommandQueue:
-lockfree queue of commands
-uses circular buffer (maybe juce::AbstractFifo)
-used for sending commands from a main/gui thread to audio thread
-main thread enqueues new commands
-has a 2nd queue with dynamic memory allocation to let the producer thread
 (main thread) store commands that currently don't fit in the buffer - they 
 will the be postponed until the next audio-buffer will be produced
-audio thread's first action inside the callback is to consume commands
-a consumed command sets an atomic int field in the command with a status 
 (initially 0: pending, 1: completed, 2: failed, higher values used for error 
 codes which can be displayed later in the gui thread)
-gui thread may delete completed commands ..or may keep them in a history
 for undo, replay, etc.
-fields for "Command":
 uint32: identifier, std::atomic<uint32> status, void* data
 
Thread-Safety:
-when the user sets a parameter (setCutoff, etc.), don't update the coeffs 
 immediately but set a "dirty" flag (of type std::atomic_bool)
-in getSample, check the flag, and if it's true, trigger the coefficient
 update there
-this also avoid recomputing the coeffs twice when the user calls setCutoff, 
 setResonance in succession

Polyphony:
-have a Voice baseclass with virtual functions like
 -noteOn(key, vel), noteOff(key, vel), setPitchBend(amount), etc.
-have a VoiceManager class that also has noteOn, etc. functions and maintains
 an array of pointers to Voice objects
-the VoiceManager is responsible for selecting to which voice the events
 will be delegated (voice allocation) and for gathering the outputs of the 
 voices in a getSample and/or processBlock function
-a dsp object, that should support polyphony, should derive from Voice and 
 maintain a pointer to its "template" or master dsp object, for example:
 
class LadderVoice : public Voice
{
  
public:
  
  void noteOn(int key, int vel) override;
  // etc...
  
protected:

  // contains the shared state (sampleRate, cutoff, reso, etc):
  Ladder* master; 
  
  // voice-specific state:
  double coeff; // may be subject to key/vel scaling of cutoff
  double y[5]   // each filter voice needs its own state variables
  //etc.
  
};

-the idea is that the voice specific state is typically small and the shared 
 state may be large for some kinds of objects and should not be stored 
 redundantly in each voice (can be accessed via the pointer to the
 template/matser object)
-to recursively compose Voice objects (a synth voice may contain 2 osc voices, 
 a filter voice, and 2 envelope voices, for example), the Voice class may 
 maintain an array of childVoice pointers
-the Voice baseclass may contain a pointer to a VoiceState object that stores 
 things like currentNote, currentVelocity, currentPitchBend, etc. - a pointer
 is used, such that this data is also not stored redundantly among a 
 SynthVoice's oscVoice, filterVoice, envVoice, etc. objects
-the overall design goal is to have a framework within which polyphonic 
 instruments can be built without storing any data redundantly
-another design goal is that the core dsp classes do not necessarily be aware
 of any polyphony stuff - for example class Ladder does not deal with any of 
 that - only the subclass LadderVoice introdcues this concept, so Ladder can 
 be used monophonically without the burden of voice-handling code
 
 
Sampler Engine
-let it use an object to take care of the streaming of the samples (from disc
 or memory)
class rsAudioStreamer
{
public:
  virtual void getSampleFrame(...);
  virtual void getBlock(...);
};
class rsAudioStreamerPreLoaded : public rsAudioStreamer
{
  // ...
};
class rsAudioStreamerDirectFromDisc : public rsAudioStreamer
{
  void setBufferSize(int numSampleFrames);
  // ...
};
class rsSamplePlayer
{
public:
  void setAudioStreamer(rsAudioStreamer* s);
protected:
  rsAudioStreamer* audioStreamer;
};
-maybe the rsSamplePlayer class (or a subclass of it) should maintain its own 
 streamer objects and be able to switch between pre-loading and disc-streaming
 via setHardDiscStreamingMode(bool)
-the streaming classes can then be re-used in a DAW app
-maybe implement the simple, preloading streamer in rosic and the more 
 complicated DFD version in jura_framework using juce classes
 -then, the sampler can't create a DFD streamer itself, it must rely on it 
  being passed in from outside code
 -a simple, pre-loading sampler-engine could be made in rosic without juce
  dependency and the DFD version would depend on juce audiofile handling
 -maybe the pre-loading engine would only support a limited set of file-formats
  to avoid juce-dependency for file loading...or maybe it wouldn't read in the
  files itself but also rely on the data being passed via a function
  setSampleData(...)

 