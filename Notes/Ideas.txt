
-------------------------------------------------------------------------------
make a class rsChoices where a 64-bit integer is used to represent a couple of
choice (i.e enum) parameters, for example, the lowest 3 bits could be used for
a parameter that has at most 8 values, the next 4 bits for a parameter with up
to 16 values etc. use a similar idea as for the rsFlags class in RSLib - with
bit-shifting and masking. that can be used for very economically storing a 
bunch of choices, when optimization memory occupation is desired. the class
could be a variadic template, using as template parameters the number of bits
for each choice parameter - for example rsChoices<3, 4, 2, 1> would encode 4 
choice parameters with 3,4,2,1 bits respectively (the latter being a boolean, 
i.e. choice between two values). the numbers passed as template parameters 
should add up to a value <= 64 (check that at compile-time)


-------------------------------------------------------------------------------
-maybe, at the lower "number crunching" level of rapt, we should take a more 
 data-oriented-design approach - see here
 https://www.youtube.com/watch?v=yy8jQgmhbAU
 maybe with things like:

struct rsBiquadCoeffs   { b0, b1, b2, a1, a2 };
struct rsBiquadStateDF1 { x1, x2, y1, y2 };
void updateBiquadState(const rsBiquadCoeffs& c, rsBiquadState& s) { ... }

-an actual biquad filter (convenience) class would then contain a coeffs and 
 state object and perhaps others (user parameters, sample-rate, etc.)
-it would make it easier to realize an array of biquads (for example, for N 
 voices) in an economic way (no (possibly redundant) parameters, sample-rates,
 etc. polluting the cache)

-------------------------------------------------------------------------------

Concepts: 
-C++20 will introduce this new language feature
-it allows to restrict the types with which client code may instantiate a 
 template
-for classes in RAPT, we often have two template types for signals and 
 parameters (often denoted as TSig, TPar)
-instead of writing
   template<class TSig, class TPar> MyClass { /* stuff */ };
 we could write
   template<SignalType TSig, ParamType TPar> MyClass { /* stuff */ };
 where SignalType and ParamType would be concepts that specify, which 
 constraints the two types must satisfy
-we could use #defines for both which evaluate to the respective concept in 
 C++20 and to "typename" or "class" in pre C++20
-a concept is more than a "type of a type" - it may also encode relationships 
 between two (or more) types. in our case, we would require (besides other 
 things) that ParamType and SignalType values can be multiplied and produce
 a SignalType (akin to scalar multiplication of vectors when signal is a SIMD 
 type and param is the underlying scalar type, for example)

-------------------------------------------------------------------------------

SmoothedValue:
-see class juce::LinearSmoothedValue
-generalize to an update equation: x[n+1] = a*x[n] + b
-allows for linear and exponential smoothing and anything between
-general term is: 
 x[n] = a^n * x[0] + b * sum_{k=0}^{n-1} a^n 
      = a^n * x0   + b * n * a^n 
	  = a^n * (x0 + b*n)
-maybe we can have a kind of "exponentiality" parameter p between 0..1
 with 0, we have linear scaling (a = 1), with 1 exponential (b = 0)
 maybe a = 1-p, b = p * c (for some suitable c, maybe 1/N (?) where N 
 is the desired number of updates to reach the target)
 
-------------------------------------------------------------------------------

CommandQueue:
-lockfree queue of commands
-uses circular buffer (maybe juce::AbstractFifo)
-used for sending commands from a main/gui thread to audio thread
-main thread enqueues new commands
-has a 2nd queue with dynamic memory allocation to let the producer thread
 (main thread) store commands that currently don't fit in the buffer - they 
 will the be postponed until the next audio-buffer will be produced
-audio thread's first action inside the callback is to consume commands
-a consumed command sets an atomic int field in the command with a status 
 (initially 0: pending, 1: completed, 2: failed, higher values used for error 
 codes which can be displayed later in the gui thread)
-gui thread may delete completed commands ..or may keep them in a history
 for undo, replay, etc.
-fields for "Command":
 uint32: identifier, std::atomic<uint32> status, void* data
 
-------------------------------------------------------------------------------
 
Thread-Safety:
-when the user sets a parameter (setCutoff, etc.), don't update the coeffs 
 immediately but set a "dirty" flag (of type std::atomic_bool)
-in getSample, check the flag, and if it's true, trigger the coefficient
 update there, the update sets the flag back to false
-this also avoids recomputing the coeffs twice when the user calls setCutoff, 
 setResonance in succession at the same sample

-------------------------------------------------------------------------------
 
Polyphony:
-have a Voice baseclass with virtual functions like
 -noteOn(key, vel), noteOff(key, vel), setPitchBend(amount), etc.
-have a VoiceManager class that also has noteOn, etc. functions and maintains
 an array of pointers to Voice objects
-the VoiceManager is responsible for selecting to which voice the events
 will be delegated (voice allocation) and for gathering the outputs of the 
 voices in a getSample and/or processBlock function
-a dsp object, that should support polyphony, should derive from Voice and 
 maintain a pointer to its "template" or master dsp object, for example:
 
class LadderVoice : public Voice
{
  
public:
  
  void noteOn(int key, int vel) override;
  // etc...
  
protected:

  // contains the shared state (sampleRate, cutoff, reso, etc):
  Ladder* master; 
  
  // voice-specific state:
  double coeff; // may be subject to key/vel scaling of cutoff
  double y[5]   // each filter voice needs its own state variables
  //etc.
  
};

-the idea is that the voice specific state is typically small and the shared 
 state may be large for some kinds of objects and should not be stored 
 redundantly in each voice (can be accessed via the pointer to the
 template/matser object)
-to recursively compose Voice objects (a synth voice may contain 2 osc voices, 
 a filter voice, and 2 envelope voices, for example), the Voice class may 
 maintain an array of childVoice pointers
-the Voice baseclass may contain a pointer to a VoiceState object that stores 
 things like currentNote, currentVelocity, currentPitchBend, etc. - a pointer
 is used, such that this data is also not stored redundantly among a 
 SynthVoice's oscVoice, filterVoice, envVoice, etc. objects
-the overall design goal is to have a framework within which polyphonic 
 instruments can be built without storing any data redundantly
-another design goal is that the core dsp classes do not necessarily be aware
 of any polyphony stuff - for example class Ladder does not deal with any of 
 that - only the subclass LadderVoice introdcues this concept, so Ladder can 
 be used monophonically without the burden of voice-handling code
 
...hmm - but the disadvantage of that is that a lot of boilerplate code would 
have to be written to make a dsp class polyphonic
-it also doesn't seem to make much sense anymore when we want to make a big 
 fraction of the data members/parameters modulatable
-what if a polyphonic modulator wants to modulate one of its own parameters? 
 it seems, we would need duplicate objects then anyway
-maybe it's actually better to just use arrays of dsp-objects (for modulation
 sources and targets) and to factor out the non-modulatable part of the state
 into a "data" class, as i have done with breakpoint modulator
-ideally, it should be possible to make *any* dsp object polyphonic with no or 
 only a minimal amount of boilerplate code - and that boilerplat code should be
 of the wire-up kind - it should not involve defining new (sub)classes
 
 maybe look at how juce does it:
 https://docs.juce.com/master/classSynthesiserVoice.html
 https://docs.juce.com/master/classSynthesiser.html
 
-------------------------------------------------------------------------------
 
Sampler Engine
-let it use an object to take care of the streaming of the samples (from disc
 or memory)
class rsAudioStreamer
{
public:
  virtual void getSampleFrame(...);
  virtual void getBlock(...);
};
class rsAudioStreamerPreLoaded : public rsAudioStreamer
{
  // ...
};
class rsAudioStreamerDirectFromDisc : public rsAudioStreamer
{
  void setBufferSize(int numSampleFrames);
  // ...
};
class rsSamplePlayer
{
public:
  void setAudioStreamer(rsAudioStreamer* s);
protected:
  rsAudioStreamer* audioStreamer;
};
-maybe the rsSamplePlayer class (or a subclass of it) should maintain its own 
 streamer objects and be able to switch between pre-loading and disc-streaming
 via setHardDiscStreamingMode(bool)
-the streaming classes can then be re-used in a DAW app
-maybe implement the simple, preloading streamer in rosic and the more 
 complicated DFD version in jura_framework using juce classes
 -then, the sampler can't create a DFD streamer itself, it must rely on it 
  being passed in from outside code
 -a simple, pre-loading sampler-engine could be made in rosic without juce
  dependency and the DFD version would depend on juce audiofile handling
 -maybe the pre-loading engine would only support a limited set of file-formats
  to avoid juce-dependency for file loading...or maybe it wouldn't read in the
  files itself but also rely on the data being passed via a function
  setSampleData(...)
  
-------------------------------------------------------------------------------

NewSynth:

general idea:
-4 sources with vector mixer
-2 filters with a sort of vector mixer that adjusts between in,1,2,1->2
-arbitray number of routable modulators
-into source, filter- and modulator slots, differnt sorts of modules can be 
 plugged in



 