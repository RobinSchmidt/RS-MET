// rasterization of filled triangles:
// https://fgiesen.wordpress.com/2013/02/08/triangle-rasterization-in-practice/

takeaway notes from scratchapixel.com

Rasterization: a Practical Implementation

Overview
https://www.scratchapixel.com/lessons/3d-basic-rendering/rasterization-practical-implementation/overview-rasterization-algorithm
-rendering can decomposed into visibility and shading. Rasterization solves the visibility problem.
-triangles are as basic rendering primitive in ray tracing and in rasterization
 -they are the simplest possible polygon and always planar (all vertices are in a plane) which 
  simplifies the math
 -together with lines and points they are the basic primitives provided by GPUs
 -any polygon can be broken down into triangles (triangulated)
-ray tracing loops in an outer loop over all pixels
 -it shoots a ray from the camera through each pixel
  -it computes intersections of this ray with all the triangles (in an inner loop) to find the one
   which is closes to the camera along the ray
-rasterization projects all triangles to the screen (in an outer loop)
 -for each projected triangle, it loops over (some subset of) all the pixels
 -for each pixel, it must figure out, if this pixel is part of the triangle, and if so, it may 
  assign a new color to the pixel
 -whether or not a new color must be assigned depends on:
  -is the triangle's surface normal directed toward the camera?
  -is the triangle in front of or behind other triangles already drawn at that pixel?
 -the color itself must be determined by a shading model
 -for anti-aliasing, the algorithm may take into account that the pixel may only be partially 
  inside the triangle
-ray tracing is image-centric, rasterization is object-centric

The Projection Stage
https://www.scratchapixel.com/lessons/3d-basic-rendering/rasterization-practical-implementation/projection-stage


The Rasterization Stage
https://www.scratchapixel.com/lessons/3d-basic-rendering/rasterization-practical-implementation/rasterization-stage
-the edge function for edge a,b and point p is the cross product between vectors (b-a) and (p-a)
-point p is inside triangle if the edge-function is positive for all 3 edges 
-OpenGL and DirectX expect triangles to be declared in counter-clockwise order
-barycentric coordinates express any point p as linear combination of the vertices of a triangle:
 p = t0*v0 + t1*v1 + t2*v2 (t stands for "triangle coordinate")
 -for points inside the triangle, we have t0,t1,t2 in 0..1 and t0 + t1 + t2 = 1
 -if known for a point in the triangle, they can be used to interpolate or extrapolate vertex 
  attributes such as color, normal vectors, texture coordinates, z-depth etc.
 -they can be computed for a point p as follows - let edg denote the edge function, then:
  s = 1/edg(v0,v1,v2), t0 = s*edg(v1,v2,p), t1 = s*edg(v2,v0,p), t2 = edg(v0,v1)
-the top-left rule considers a point on the edge as inside, if it's on a top or left edge
 -a top edge is perfectly horizontal above the third vertex
 -a left edge is an edge that is going down (in counter-clockwise vertex order convention)
 -important for cases where the edge function is 0

The Visibility Problem, the Depth Buffer Algorithm and Depth Interpolation
https://www.scratchapixel.com/lessons/3d-basic-rendering/rasterization-practical-implementation/visibility-problem-depth-buffer-depth-interpolation
-the z-buffer (or depth buffer) stores the (projected) z-coordinate for each pixel for the last
 triangle that has (over)written the pixel (it's initialized with large/inf values)
-when a new triangle (that overlaps the pixel) is encountered, we compute a z-value for the new 
 triangle at the pixel (by inverse barycentric interpolation) and compare it to the value already 
 in the buffer
 -when the new z-value is less than the stored value, the pixel's color and z-buffer value are
  overwritten
-to find an interpolated z-depth value of a point on a triangle whose vertices were projected 
 via perspective projection, we need to interpolate the reciprocals of the projected z-values
 
Perspective Correct Interpolation and Vertex Attributes
https://www.scratchapixel.com/lessons/3d-basic-rendering/rasterization-practical-implementation/perspective-correct-interpolation-vertex-attributes
-to interpolate a vertex attribute, we first divide by the z-coordinate of the vertex, then 
 linearly interpolate, and finally multiply by Z, which is the depth of the point on the triangle
 (obtained by reciprocal linear/barycentric interpolation as explained above)
 
Rasterization: a Practical Implementation 
https://www.scratchapixel.com/lessons/3d-basic-rendering/rasterization-practical-implementation/rasterization-practical-implementation
-pixels may be divided into a N by N number of sub-pixels where N is generally a power of 2
-one may render blocks of pixels - rather than testing all pixels in the block, we first test 
 corner pixels - if they are contained in a triangle, the interior piyled will also be
-when the edge-function is called for many pixels in the same triangle, an incremental evaluation
 is possible by precomputing triagle related variables, the per-pixel update is only an addition
-vertex attributes need to be "pre-divided" by these vertices z-coordinates for perspective correct
 interpolation). It is usually done just before the triangle gets rendered (just before the loop 
 that iterates over the pixels). 
-rasterization uses an outer loop over the triangles and the inner loop iterates over the pixels 
 contained in the current triangle's bounding box
-each pixel is tested for coverage using the edge function. If a pixel covers a triangle, we 
 compute the pixel barycentric coordinates with respect to the triangle. we use these coordinates 
 to compute the depth. If we pass the depth buffer test, we then update the buffer with the new 
 depth value and update the frame-buffer with the triangle's color (barycentrically interpolated at
 the pixel's barycentric coordinates)
-the facing ratio is the dot product between the triangle normal and the view direction, which is 
 the vector defined by the point P on the triangle camera position E. Since all points at this 
 the camera position is E=(0,0,0). Thus the view direction is simply -P which then needs to be 
 normalized. The dot product can be negative so we need to clamp it (we only want positive values). 
-back-face culling: Don't render the triangle if the dot product of its normal and the view 
 direction is lower than a certain threshold

